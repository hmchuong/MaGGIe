{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a810e34-f64d-4813-af51-f7277a1da4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c8ef8-44b3-4881-ae5c-cd8ed5d03293",
   "metadata": {},
   "source": [
    "## Binary mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ffaa3aa-8e40-4e18-8091-654b24e484b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/mnt/localssd/VideoMatte240K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c01cb37-7a57-4da8-8ddc-2effa4ec76b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2720/2720 [03:19<00:00, 13.62it/s]\n"
     ]
    }
   ],
   "source": [
    "split = \"test\"\n",
    "threshold = 0.5\n",
    "alpha_dir = os.path.join(data_dir, split, \"pha\")\n",
    "out_dir = os.path.join(data_dir, split, \"bin\")\n",
    "for alpha_path in tqdm(glob.glob(alpha_dir + \"/*/*\")):\n",
    "    alpha = np.array(Image.open(alpha_path).convert(\"L\"))\n",
    "    binmask = (alpha > threshold * 255) * 255\n",
    "    out_path = alpha_path.replace(alpha_dir, out_dir)\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    cv2.imwrite(out_path, binmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2055d169-11a5-4787-ad17-438a4eb2eead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2773/2773 [02:01<00:00, 22.87it/s]\n"
     ]
    }
   ],
   "source": [
    "split = \"valid\"\n",
    "threshold = 0.5\n",
    "alpha_dir = os.path.join(data_dir, split, \"pha\")\n",
    "out_dir = os.path.join(data_dir, split, \"bin\")\n",
    "for alpha_path in tqdm(glob.glob(alpha_dir + \"/*/*\")):\n",
    "    alpha = np.array(Image.open(alpha_path).convert(\"L\"))\n",
    "    binmask = (alpha > threshold * 255) * 255\n",
    "    out_path = alpha_path.replace(alpha_dir, out_dir)\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    cv2.imwrite(out_path, binmask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5642d701-4057-44d4-afa0-570ee8a57d1a",
   "metadata": {},
   "source": [
    "## Propagate the binary mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390df74a-77f0-41a8-9731-c731d0fa9d08",
   "metadata": {},
   "source": [
    "## Tri-map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8fc3a3c-1bef-4670-ab83-8258bc86d5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_trimap(alpha, eval_kernel=25):\n",
    "    k_size = eval_kernel\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,\n",
    "                                       (k_size, k_size))\n",
    "    dilated = cv2.dilate(alpha, kernel)\n",
    "    eroded = cv2.erode(alpha, kernel)\n",
    "    trimap = np.zeros(alpha.shape)\n",
    "    trimap.fill(128)\n",
    "    # cv2.imwrite(\"dilated.png\", dilated)\n",
    "    # cv2.imwrite(\"eroded.png\", eroded)\n",
    "    # print((eroded > 254.5).sum())\n",
    "    # print((dilated < 10).sum())\n",
    "    trimap[eroded > 254.5] = 255\n",
    "    trimap[dilated < 10] = 0\n",
    "    return trimap, eroded, dilated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9154a0a6-3618-4215-93d5-511eed1b0015",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2720/2720 [09:49<00:00,  4.61it/s]\n"
     ]
    }
   ],
   "source": [
    "split = \"test\"\n",
    "threshold = 0.5\n",
    "alpha_dir = os.path.join(data_dir, split, \"pha\")\n",
    "out_dir = os.path.join(data_dir, split, \"tri\")\n",
    "for alpha_path in tqdm(glob.glob(alpha_dir + \"/*/*\")):\n",
    "    alpha = np.array(Image.open(alpha_path).convert(\"L\"))\n",
    "    # binmask = (alpha > threshold * 255) * 255\n",
    "    trimap, _, _ = gen_trimap(alpha)\n",
    "    out_path = alpha_path.replace(alpha_dir, out_dir)\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    cv2.imwrite(out_path, trimap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ae3cec3-012d-4ef0-8225-bd4ea0b24051",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2773/2773 [05:58<00:00,  7.73it/s]\n"
     ]
    }
   ],
   "source": [
    "split = \"valid\"\n",
    "threshold = 0.5\n",
    "alpha_dir = os.path.join(data_dir, split, \"pha\")\n",
    "out_dir = os.path.join(data_dir, split, \"tri\")\n",
    "for alpha_path in tqdm(glob.glob(alpha_dir + \"/*/*\")):\n",
    "    alpha = np.array(Image.open(alpha_path).convert(\"L\"))\n",
    "    # binmask = (alpha > threshold * 255) * 255\n",
    "    trimap, _, _ = gen_trimap(alpha)\n",
    "    out_path = alpha_path.replace(alpha_dir, out_dir)\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    cv2.imwrite(out_path, trimap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5e55a0-b2e4-48f0-9e5b-18601aa66483",
   "metadata": {},
   "source": [
    "## Propagate the tri-map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36dd532-bbd6-4176-a07c-5e83ac848ab4",
   "metadata": {},
   "source": [
    "## Compute flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d02ca826-3dc1-450c-baf4-b17459b5945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('RAFT/core')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deed8e52-e924-4762-88e3-5e481027b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from raft import RAFT\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8cf381e8-2b1a-4477-9fc2-f4a9af2df9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small=False\n",
    "mixed_precision=False\n",
    "alternate_corr=False\n",
    "args = Namespace(small=small, mixed_precision=mixed_precision, alternate_corr=alternate_corr)\n",
    "raft_model = RAFT(args).cuda()\n",
    "state_dict = torch.load('RAFT/models/raft-sintel.pth')\n",
    "state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "raft_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4ee4c97-5941-4351-b3b9-029e8f400ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = raft_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b4420c6-7c67-4d43-981c-b0964afd723a",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"test\"\n",
    "img_dir = os.path.join(data_dir, split, \"fgr\")\n",
    "out_dir = os.path.join(data_dir, split, \"flow\")\n",
    "\n",
    "image_paths = sorted(glob.glob(img_dir + \"/*/*\"))\n",
    "image_pairs = [(image_paths[i], image_paths[i + 1]) for i in range(len(image_paths) - 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc42d44d-318a-4f2f-9a31-384ad6ef3d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l_img_path, r_img_path in image_pairs:\n",
    "    left = np.array(cv2.imread(l_img_path)[:, :, ::-1])\n",
    "    right = np.array(cv2.imread(r_img_path)[:, :, ::-1])\n",
    "    alpha_left = cv2.imread(l_img_path].replace(\"fgr\", \"pha\"))\n",
    "    if len(alpha_left.shape) > 2:\n",
    "        alpha_left = alpha_left[:, :, 0]\n",
    "    alpha_right = cv2.imread(r_img_path.replace(\"fgr\", \"pha\"))\n",
    "    if len(alpha_right.shape) > 2:\n",
    "        alpha_right = alpha_right[:, :, 0]\n",
    "    \n",
    "    # Check ROI\n",
    "    x1, y1, x2, y2 = 0, 0, left.shape\n",
    "    ys, xs = np.where(alpha_left > 10)\n",
    "    ys.min(), ys.max(), xs.min(), xs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef4ca3ba-e2d1-493a-a15f-467e3336049b",
   "metadata": {},
   "outputs": [],
   "source": [
    "left = torch.from_numpy(left).permute(2, 0, 1)[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d1ab3d3-47a5-47cf-8f08-6b49ee396e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "right = torch.from_numpy(right).permute(2, 0, 1)[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60ca6d68-e9e4-4ed1-89e4-a6f3074b14df",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 62.57 GiB (GPU 0; 22.02 GiB total capacity; 808.62 MiB already allocated; 18.43 GiB free; 1.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 2\u001b[0m     _, flow1 \u001b[38;5;241m=\u001b[39m \u001b[43mraft_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/mask2matte/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/sensei-fs/users/chuongh/vm2m/tools/RAFT/core/raft.py:107\u001b[0m, in \u001b[0;36mRAFT.forward\u001b[0;34m(self, image1, image2, iters, flow_init, upsample, test_mode)\u001b[0m\n\u001b[1;32m    105\u001b[0m     corr_fn \u001b[38;5;241m=\u001b[39m AlternateCorrBlock(fmap1, fmap2, radius\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mcorr_radius)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m     corr_fn \u001b[38;5;241m=\u001b[39m \u001b[43mCorrBlock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfmap1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmap2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr_radius\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# run the context network\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast(enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mmixed_precision):\n",
      "File \u001b[0;32m/sensei-fs/users/chuongh/vm2m/tools/RAFT/core/corr.py:19\u001b[0m, in \u001b[0;36mCorrBlock.__init__\u001b[0;34m(self, fmap1, fmap2, num_levels, radius)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorr_pyramid \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# all pairs correlation\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m corr \u001b[38;5;241m=\u001b[39m \u001b[43mCorrBlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfmap1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmap2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m batch, h1, w1, dim, h2, w2 \u001b[38;5;241m=\u001b[39m corr\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     22\u001b[0m corr \u001b[38;5;241m=\u001b[39m corr\u001b[38;5;241m.\u001b[39mreshape(batch\u001b[38;5;241m*\u001b[39mh1\u001b[38;5;241m*\u001b[39mw1, dim, h2, w2)\n",
      "File \u001b[0;32m/sensei-fs/users/chuongh/vm2m/tools/RAFT/core/corr.py:58\u001b[0m, in \u001b[0;36mCorrBlock.corr\u001b[0;34m(fmap1, fmap2)\u001b[0m\n\u001b[1;32m     55\u001b[0m fmap1 \u001b[38;5;241m=\u001b[39m fmap1\u001b[38;5;241m.\u001b[39mview(batch, dim, ht\u001b[38;5;241m*\u001b[39mwd)\n\u001b[1;32m     56\u001b[0m fmap2 \u001b[38;5;241m=\u001b[39m fmap2\u001b[38;5;241m.\u001b[39mview(batch, dim, ht\u001b[38;5;241m*\u001b[39mwd) \n\u001b[0;32m---> 58\u001b[0m corr \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfmap1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmap2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m corr \u001b[38;5;241m=\u001b[39m corr\u001b[38;5;241m.\u001b[39mview(batch, ht, wd, \u001b[38;5;241m1\u001b[39m, ht, wd)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m corr  \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(torch\u001b[38;5;241m.\u001b[39mtensor(dim)\u001b[38;5;241m.\u001b[39mfloat())\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 62.57 GiB (GPU 0; 22.02 GiB total capacity; 808.62 MiB already allocated; 18.43 GiB free; 1.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    _, flow1 = raft_model(left.cuda(), right.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbced13f-395f-4c39-ad0c-bcf5fbea3692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 2160, 3840])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "386d7950-98fd-4a3a-b796-7a2f85804797",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_left = cv2.imread(image_pairs[0][0].replace(\"fgr\", \"pha\"))[:, :, 0]\n",
    "alpha_right = cv2.imread(image_pairs[0][1].replace(\"fgr\", \"pha\"))[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "075ed659-d38b-4157-b43a-a56e25a7ea92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 2159, 1985, 3663)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys, xs = np.where(alpha_left > 10)\n",
    "ys.min(), ys.max(), xs.min(), xs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8cd270a5-5748-42a0-b9b4-d0e6315270d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 2159, 1985, 3660)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys, xs = np.where(alpha_right > 10)\n",
    "ys.min(), ys.max(), xs.min(), xs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c069381-b153-4739-901d-8ff72c09ecbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mask2matte_2",
   "language": "python",
   "name": "mask2matte_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

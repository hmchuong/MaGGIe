name: 'mgm_enc-dec_ft-hhm_short-576-512x512_bs32_50k_adamw_1e-4'
output_dir: 'output/HHM'
train:
  batch_size: 12
  num_workers: 4
  max_iter: 50000
  optimizer:
    lr: 5.0e-5
    name: adamw
  scheduler:
    name: cosine
    warmup_iters: 1000
  val_metrics: ['MAD', 'MSE', 'SAD']
  val_best_metric: 'MAD'
  val_iter: 500
  vis_iter: 50
  log_iter: 10
  seed: 1105
test:
  num_workers: 4
  metrics: ['MAD', 'MSE', 'SAD']
model:
  arch: 'MGM'
  weights: output/HIM/mgm_enc-dec_multi-inst_him_bs12_2gpus_best0804/best_model.pth
  backbone: res_embed_shortcut_encoder_29
  backbone_args:
    num_embed: 3
    num_mask: 10
    pretrained: true
  decoder: res_shortcut_embed_attention_decoder_22
  decoder_args:
    atten_block: 2
    atten_dim: 128
    atten_head: 1
    atten_stride: 1
    final_channel: 64
    head_channel: 50
    max_inst: 10
  mgm:
    warmup_iter: 0
  loss_alpha_grad_w: 0.0
  loss_alpha_lap_w: 1.0
  loss_alpha_type: l1
  loss_alpha_w: 1.0
  loss_atten_w: 1.0
  loss_comp_w: 0.0
  loss_dtSSD_w: 0.0
  loss_multi_inst_w: 0.0
dataset:
  train:
    name: 'HHM'
    root_dir: '/mnt/localssd/HHM'
    bg_dir: /mnt/localssd/bg
    split: 'train'
    # short_size: 768
    short_size: 576
  test:
    name: 'HHM'
    root_dir: '/mnt/localssd/HHM'
    split: 'val'
    # short_size: 768
    short_size: 576
name: 'mgm_atten-dec'
output_dir: 'output/AM-2K'
train:
  batch_size: 30
  num_workers: 10
  max_iter: 50000
  optimizer:
    lr: 2.0e-4
    name: adamw
  scheduler:
    name: cosine
    warmup_iters: 1000
  val_metrics: ['MAD', 'MSE', 'SAD']
  val_best_metric: 'MAD'
  val_iter: 1000
  vis_iter: 200
  log_iter: 50
test:
  num_workers: 4
  metrics: ['MAD', 'MSE', 'SAD']
  postprocessing: False
  use_trimap: False
  log_iter: 1
  save_results: False
model:
  arch: 'MGM'
  backbone: 'res_shortcut_encoder_29'
  backbone_args:
    num_mask: 0
  decoder: 'res_shortcut_attention_decoder_22'
  decoder_args:
    final_channel: 32
    atten_dims: [32, 32, 32]
    atten_strides: [4, 2, 2]
    atten_blocks: [2, 2, 2]
    atten_heads: [1, 1, 1]
  mgm:
    warmup_iter: 5000
  loss_dtSSD_w: 0.0
  loss_comp_w: 0.0
dataset:
  train:
    name: 'HHM'
    root_dir: '/mnt/localssd/HHM'
    split: 'train'
  test:
    name: 'HHM'
    root_dir: '/mnt/localssd/AM-2K'
    split: 'val'
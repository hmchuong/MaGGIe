name: 'mgm_atten-dec_vid240_pre-hmm_s-768-512x512_b4-f8_100k_adamw_1e-4'
output_dir: 'output/HHM'
train:
  batch_size: 6
  num_workers: 4
  max_iter: 100000
  optimizer:
    lr: 1.0e-4
    name: adamw
  scheduler:
    name: cosine
    warmup_iters: 1000
  val_metrics: ['MAD', 'MSE', 'dtSSD']
  val_best_metric: 'MAD'
  val_iter: 1000
  vis_iter: 200
  log_iter: 50
test:
  num_workers: 4
  metrics: ['MAD', 'MSE', 'SAD', 'Conn', 'Grad']
model:
  arch: 'MGM'
  weights: 'output/HHM/mgm_atten-dec_hhm_short-768-512x512_bs32_50k_adamw_2e-4/best_model.pth'
  backbone: 'res_shortcut_encoder_29'
  backbone_args:
    num_mask: 0
  decoder: 'res_shortcut_attention_decoder_22'
  decoder_args:
    final_channel: 32
    atten_dims: [32, 32, 32]
    atten_strides: [4, 2, 2]
    atten_blocks: [2, 2, 2]
    atten_heads: [1, 1, 1]
  mgm:
    warmup_iter: 0
  loss_dtSSD_w: 1.0
  loss_comp_w: 1.0
dataset:
  train:
    root_dir: '/mnt/localssd/VideoMatte240K'
    bg_dir: '/mnt/localssd/bg'
    short_size: 768
    clip_length: 5
  test:
    root_dir: '/mnt/localssd/VideoMatte240K'
    short_size: 768
    clip_length: 5
    clip_overlap: 2
dataset:
  test:
    alpha_dir_name: pha
    clip_length: 3
    clip_overlap: 2
    downscale_mask: false
    mask_dir_name: ''
    name: MultiInstVideo
    root_dir: /mnt/localssd/syn/benchmark
    short_size: 576
    split: comp_medium
    use_thresh_mask: false
  train:
    bg_dir: ''
    bin_alpha_max_k: 30
    blur_kernel_size:
    - 5
    - 15
    - 25
    blur_prob: 0.5
    blur_sigma:
    - 1.0
    - 1.5
    - 3.0
    - 5.0
    clip_length: 8
    crop:
    - 512
    - 512
    downscale_mask: false
    downscale_mask_p: 0.5
    flip_prob: 0.5
    mask_dir_name: xmem
    max_inst: 2
    max_step_size: 5
    modify_mask_p: 0.1
    name: MultiInstVideo
    padding_inst: 10
    random_state: 2023
    root_dir: /mnt/localssd/syn
    short_size: 576
    split: train
    ss_split: pexels-train
    use_maskrcnn_p: 0.2
    use_single_instance_only: true
model:
  sync_bn: true
  arch: MGM_SS
  # arch: MGM
  aspp:
    in_channels: 512
    out_channels: 512
  backbone: res_embed_shortcut_os8_encoder_29
  backbone_args:
    num_embed: 3
    num_mask: 10
    pretrained: true
    shortcut_dropout: 0.0
  breakdown:
    in_channels:
    - 32
    - 32
    - 32
    in_features:
    - os4
    - os1
  # decoder: res_shortcut_attention_spconv_inconsisttemp_decoder_22
  # decoder: res_shortcut_attention_spconv_decoder_22
  decoder: res_shortcut_attention_spconv_bitempspar_decoder_22
  decoder_args:
    atten_block: 2
    atten_dim: 128
    atten_head: 1
    atten_stride: 1
    embed_dim: 3
    final_channel: 64
    head_channel: 120
    max_inst: 10
    stm_dropout: 0.0
    use_detail_temp: False
    use_id_pe: True
    # use_query_temp: False
    use_query_temp: False #'mlp'
    warmup_mask_atten_iter: 0
    warmup_detail_iter: 0 #1000
    temp_method: 'bi_fusion'
  dynamic_kernel:
    dec_layers: 5
    dim_feedforward: 256
    enforce_input_project: true
    hidden_dim: 256
    in_channels: 256
    in_features:
    - os32
    - os16
    - os8
    nheads: 4
    out_incoherence: 157
    out_pixeldecoder: 864
    pre_norm: false
  loss_alpha_grad_w: 0.0 #25
  loss_alpha_lap_w: 0.25
  loss_alpha_type: l1
  loss_alpha_w: 1.0
  loss_atten_w: 1.0
  loss_comp_w: 0.0
  loss_dtSSD_w: 1.0
  loss_multi_inst_type: smooth_l1_0.5
  loss_multi_inst_w: 0.25
  loss_multi_inst_warmup: 0 #1500
  mgm:
    warmup_iter: 0 #1000
  refinement:
    n_test_points: 16000
    n_train_points: 2048
  shm:
    dilation_kernel: 15
    lr_scale: 0.5
    max_n_pixel: 4000000
    mgm_weights: ''
  shortcut_dims:
  - 32
  - 32
  - 64
  - 128
  - 256
  weights: output/VHM/ours_vhm_atten-conv-gru-os8-x2/best_model.pth
name: ours_ss_1022
output_dir: output/VHM
test:
  batch_size: 1
  log_iter: 50
  metrics:
  - MAD
  - MSE
  - SAD
  - dtSSD
  num_workers: 4
  postprocessing: false
  save_dir: logs
  save_results: true
  temp_aggre: false
  use_trimap: true
train:
  batch_size: 6
  log_iter: 1
  self_train:
    use: true
    max_cycles: 10
    epoch_per_cycle: 10
    iter_per_epoch: 500
    start_ratio: 0.01
    end_ratio: 0.2
  num_workers: 8
  optimizer:
    betas:
    - 0.9
    - 0.999
    lr: 0.00001
    momentum: 0.9
    name: adamw
    weight_decay: 0.01
  resume: ''
  resume_last: true
  scheduler:
    gamma: 0.1
    name: cosine
    power: 0.9
    step_size: 10000
    warmup_iters: 1000
  seed: 1105
  val_best_metric: MAD
  val_dist: False
  val_iter: 500
  val_metrics:
  - MAD
  - MSE
  - SAD
  - dtSSD
  vis_iter: 50
wandb:
  entity: research-dmo
  id: ''
  project: video-maskg-matting
  use: true
